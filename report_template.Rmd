---
title: "Research Report: PROJECT-TITLE"
subtitle: "UNILU Big Data Analytics Group Examination: GROUPNAME"
author:
- Author1 (Student ID)
- Author2 (Student ID)
- Author3 (Student ID)
- Author4 (Student ID)

date: "19/06/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction (max. 500 words)

## Research Question

## Data Source(s)

## Summary of Methods and Results



# Data Collection and Data Storage (max. 500 words, not including code and code comments)


<!-- Describe how you approach the data collection procedure. In your research setting, what were the challenges regarding collecting the raw data. How did you solve these challenges? How do you store the raw data and why?  -->


```{r}

# Either paste your data collection code here or refer to it via source("code/mycode.R")

```



# Data Cleaning and Preparation (max. 500 words, not including code and code comments)

<!-- Describe the challenges related to cleaning/filtering your raw data in order to prepare an analytic data set. What were the bottle necks (which tasks and which hardware resources)? How did you speed up/improve the data cleaning procedure for large amounts of data? Which tools/techniques did you use and how do these tools/techniques work?   -->


```{r}

# Either paste your data preparation code here or refer to it via source("code/mycode.R")

```



#  Data Analysis and Data Visualization (max. 500 words, not including code and code comments)

<!-- Explain how you analyzed the data (which method(s) were used and why). Then explain what the challenges were in implementing these analyses, given the large amount of data. Finally, explain which tools/techniques you have used in order to tackle these challenges. Make sure to briefly point out why you have chosen these tools/techniques and how they helped.   -->


```{r}

# Either paste your data analysis code here or refer to it via source("code/mycode.R")

```


# Results (max. 5 exhibits [figures/tables] and 500 words)



<!-- First, briefly summarize your main findings. Then, show up to 5 exhibits (tables and figures). Right below each table/figure, add table/figure-notes that describe what the reader sees in the corresponding table/figure. (Hint: have a look at empirical papers in the top Econ outlets like AER, QJE, Econometrica, etc. to get a feeling for how Economists write such notes.) -->


```{r}

# Refer to the script(s) that generate the figures/tables via source("code/mycode.R") here

```




# Scaling and Cloud Deployment (max. 500 words, not including code and code comments)


<!-- Almost done! In this last section, suppose you have to re-run your data pipeline with substantially more data. Further suppose that you have access to cloud resources to scale up/scale out the different components of your pipeline. Briefly describe which cloud solutions you would use for which part of your analysis and explain why. Note: as in the explanations above, this part is also very project-specific. Some cloud solutions probably make sense for some projects but would be overkill in other projects, etc.  -->



